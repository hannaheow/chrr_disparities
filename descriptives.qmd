---
title: "descriptives"
#format: pdf
execute:
  echo: false      # This hides the code from being printed
  warning: false   # This suppresses warnings
  message: false   # This suppresses messages
  error: false
  results: 'markup' # This ensures that only results are displayed
output:
  html_document: 
  self_contained: true 
---

```{r get data into a usable form }
library(tidyverse)
# Load each file and assign to a new variable name

assign("tract", get(load("calcd_data_how/tract_cis_all_years.RData")))
assign("race", get(load("calcd_data_how/race_cis_all_years.RData")))
assign("income", get(load("calcd_data_how/income_cis_all_years.RData")))
income$year = as.character(income$year)

# Function to rename columns except the first three
rename_columns_cis <- function(df, dataset_name) {
  df %>%
    rename_with(~ ifelse(. %in% c("statecode", "countycode", "fipscode", "GEOID", "year"), ., paste0(dataset_name, "_", .)))
  #, -c(statecode, countycode, fipscode, GEOID))
}

# Rename columns for tract, race, and income
tract <- rename_columns_cis(tract, "tract")
race <- rename_columns_cis(race, "race")
income <- rename_columns_cis(income, "income")

# merge all together
# set all sd_bgv_wt to NA when they are equal to 0 - this is valid because in the calculations step, we consistently use na.rm= TRUE which means that when the 0s occur, this indicates that there were no valid values 
all <- tract %>%
  left_join(race, by = c("statecode", "countycode", "year")) %>%
  left_join(income, by = c("statecode", "countycode", "year")) %>% 
  mutate(race_sd_bgv_wt = ifelse(race_sd_bgv_wt == 0, NA, race_sd_bgv_wt), 
         income_sd_bgv_wt = ifelse(income_sd_bgv_wt == 0, NA, income_sd_bgv_wt),
         tract_sd_bgv_wt = ifelse(tract_sd_bgv_wt == 0, NA, tract_sd_bgv_wt))
all23 = all %>% filter(year == 2023)
```


Across US counties, the median county-level disparity in homeownership rates across income groups is 

```{r}
median(all23$income_sd_bgv_wt, na.rm = TRUE)

median(all23$tract_sd_bgv_wt, na.rm = TRUE)

median(all23$race_sd_bgv_wt, na.rm = TRUE)


sum(is.na(all$income_sd_bgv_wt))

sum(is.na(all$tract_sd_bgv_wt))

sum(is.na(all$race_sd_bgv_wt)) 


```


There are some differences across urbanicity categories 

```{r make bar plot by urb category - can change from two to nine if needed }
urbcodes = readxl::read_xlsx("inputs/Ruralurbancontinuumcodes2023.xlsx")
urbcodes <- urbcodes %>% mutate(FIPS = as.numeric(FIPS), # Ensure numeric for join
                                ShortDesc = sub(" -.*", "", Description))  # create metro/nonmetro variable 
all23 = all23 %>% mutate(fipscode = as.numeric(fipscode.x))
all_urb <- left_join(all23, urbcodes, by = c("fipscode" = "FIPS"))

all_urb %>% group_by(RUCC_2023) %>% summarize(median(median(income_sd_bgv_wt, na.rm = TRUE)))
all_urb %>% group_by(RUCC_2023) %>% summarize(median(median(race_sd_bgv_wt, na.rm = TRUE)))
all_urb %>% group_by(RUCC_2023) %>% summarize(median(median(tract_sd_bgv_wt, na.rm = TRUE)))


library(dplyr)
library(tidyr)
library(ggplot2)
library(forcats)

# Summarize the three variables into long format
plot_data <- all_urb %>%
  group_by(ShortDesc) %>%
  summarize(
    Income = median(income_sd_bgv_wt, na.rm = TRUE),
    Race   = median(race_sd_bgv_wt, na.rm = TRUE),
    Tract  = median(tract_sd_bgv_wt, na.rm = TRUE)
  ) %>%
  pivot_longer(
    cols = c(Income, Race, Tract),
    names_to = "Measure",
    values_to = "MedianDisparity"
  )

ggplot(plot_data, aes(x = MedianDisparity, y = ShortDesc, fill = Measure)) +
  geom_col(position = "dodge") +
  labs(
    title = "Disparities by RUCC Category",
    x = "Median SD of population-weighted group means",
    y = NULL, 
    fill = ""
  ) +
  theme_minimal(base_size = 12) +
  theme(
    legend.position = "top",
    axis.text.y = element_text(size = 9)
  )

```


# overall correlation 
use pearsons since vals are normally dist and continuous 
```{r}
library(psych)
# Subset the relevant variables
vars <- all_urb[, c("tract_sd_bgv_wt", "income_sd_bgv_wt", "race_sd_bgv_wt")]

# Calculate Pearson's correlations with confidence intervals
corr_results <- corr.test(vars, method = "pearson", adjust = "none", ci = TRUE)

# Print correlation matrix
print(corr_results$r)

# Print conf int 
print(corr_results$ci)



```

# correlations by group 

```{r}
library(psych)
library(dplyr)

# Initialize empty data frame to store results
cor_summary <- data.frame(
  RUCC_2023 = character(),
  var1 = character(),
  var2 = character(),
  r = numeric(),
  ci_lower = numeric(),
  ci_upper = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each group
for (group in unique(all_urb$RUCC_2023)) {
  
  # Subset and clean
  group_data <- subset(all_urb, RUCC_2023 == group)
  vars <- na.omit(group_data[, c("tract_sd_bgv_wt", "income_sd_bgv_wt", "race_sd_bgv_wt")])
  
  if (nrow(vars) < 3) next  # skip if not enough data
  
  # Correlation with CI
  corr <- corr.test(vars, method = "pearson", adjust = "none", ci = TRUE)
  
  # Extract r, ci lower, ci upper
  r <- corr$r
  ci_lower <- corr$ci.lower
  ci_upper <- corr$ci.upper
  
  var_names <- colnames(r)
  
  # Loop through upper triangle to extract pairs
  for (i in 1:(ncol(r) - 1)) {
    for (j in (i + 1):ncol(r)) {
      cor_summary <- rbind(cor_summary, data.frame(
        RUCC_2023 = group,
        var1 = var_names[i],
        var2 = var_names[j],
        r = round(r[i, j], 3),
        ci_lower = round(ci_lower[i, j], 3),
        ci_upper = round(ci_upper[i, j], 3)
      ))
    }
  }
}

# Optional: add formatted column
cor_summary <- cor_summary %>%
  mutate(r_ci = paste0(r, " (", ci_lower, ", ", ci_upper, ")"))

# View table
print(cor_summary)

# Optional: write to CSV
# write.csv(cor_summary, "grouped_correlations.csv", row.names = FALSE)

```



```{r CORRELATIONS BY URB GROUP}
library(dplyr)
library(tidyr)
library(purrr)

# Select relevant columns and group by RUCC_2023
correlations_by_group <- all_urb %>%
  select(RUCC_2023, income_sd_bgv_wt, race_sd_bgv_wt, tract_sd_bgv_wt) %>%
  group_by(RUCC_2023) %>%
  filter(!is.na(income_sd_bgv_wt) & !is.na(race_sd_bgv_wt) & !is.na(tract_sd_bgv_wt)) %>%
  group_split() %>%
  map_df(function(group_df) {
    cor_matrix <- cor(group_df[, c("income_sd_bgv_wt", "race_sd_bgv_wt", "tract_sd_bgv_wt")], use = "complete.obs")
    
    # Convert correlation matrix to tidy format
    tidy_cor <- as.data.frame(as.table(cor_matrix)) %>%
      filter(Var1 != Var2) %>%
      mutate(RUCC_2023 = unique(group_df$RUCC_2023)) %>%
      select(RUCC_2023, Var1, Var2, Correlation = Freq)
    
    return(tidy_cor)
  })

```


```{r correlations by group data visualized }

ggplot(correlations_by_group, aes(x = Var1, y = Var2, fill = Correlation)) +
  geom_tile(color = "white") +
  facet_wrap(~ RUCC_2023) +
  scale_fill_gradient2(
    low = "blue", mid = "white", high = "red", 
    midpoint = 0, limit = c(-1, 1), 
    name = "Correlation"
  ) +
  labs(
    title = "Correlation Between Disparity Measures by Group",
    x = NULL, y = NULL
  ) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    strip.text = element_text(size = 10, face = "bold")
  )

```










################################################################################
# SCRATCH 

```{r get the mapping function ready}
library(tigris)
library(ggplot2)
library(dplyr)
library(sf)

# Load county shapefile
#counties <- counties(cb = TRUE, resolution = '20m') %>%  st_as_sf() %>%  rename(statecode = STATEFP, countycode = COUNTYFP) 
#save(counties, file = "inputs/counties_shp.RData")

# Merge data with county shapefile
load("inputs/counties_shp.RData")

map_data <- left_join(counties, all, by = c("statecode", "countycode"))

# Select columns that contain "sd_bgv_wt" in their name
sd_bgv_wt_columns <- map_data %>% 
  select(contains("sd_bgv_wt")) %>% st_drop_geometry()

# Calculate global minimum and maximum of the selected columns
#global_min <- min(sd_bgv_wt_columns, na.rm = TRUE)
#global_max <- max(sd_bgv_wt_columns, na.rm = TRUE)

# Set specific columns to NA if they are 0
map_data <- map_data %>%
  mutate(across(c(tract_cis_sd_bgv_wt, race_cis_sd_bgv_wt, income_cis_sd_bgv_wt), 
                ~if_else(. == 0, NA_real_, .)))


# Create map plotting function
plot_map <- function(column, title, legend = TRUE) {
  ggplot(map_data) +
    geom_sf(aes_string(fill = column), color = NA) +
    scale_fill_viridis_c(option = "plasma", na.value = "grey80", limits = c(min(map_data[[column]], na.rm = TRUE), max(map_data[[column]], na.rm = TRUE))
    ) +
    theme_minimal(base_size = 14) +
    theme(
      plot.margin = margin(5, 5, 5, 5),
      panel.grid = element_blank(),
      legend.position = if (legend) "right" else "none"
    ) +
    coord_sf(crs = 5070) +  # Standard Albers Equal Area projection
    labs(fill = title, title = title)
}




```

## Maps with unstable estimates removed

The coasts (California and New England) appear to have high tract and income disparities but possibly lower race disparities. Perhaps we should do some regional and/or state-level exploration.

```{r}
# Plot each map
plot_tract <- plot_map("tract_cis_sd_bgv_wt", "SD across Tracts", legend = FALSE)
plot_income <- plot_map("income_cis_sd_bgv_wt", "SD across Income", legend = FALSE)
plot_race_wlegend <- plot_map("race_cis_sd_bgv_wt", "SD across Race/Ethnicities")

plot_tract
plot_income
plot_race_wlegend
```

## Histograms of SD for Race, Income, Tract

```{r histograms for urb cats}


urbcodes = readxl::read_xlsx("inputs/Ruralurbancontinuumcodes2023.xlsx")
urbcodes <- urbcodes %>% mutate(FIPS = as.numeric(FIPS))  # Ensure numeric for join
all = all %>% mutate(fipscode = as.numeric(fipscode.x))
all_urb <- left_join(all, urbcodes, by = c("fipscode" = "FIPS"))


# Set specific columns to NA if they are 0
hist_data <- all_urb %>%
  mutate(across(c(tract_cis_sd_bgv_wt, race_cis_sd_bgv_wt, income_cis_sd_bgv_wt), 
                ~if_else(. == 0, NA_real_, .)))


tworucc = hist_data %>% group_by(RUCC_2023) %>% 
  mutate(RUCC_group = ifelse(RUCC_2023 %in% c(1,2,3), "Urban", "Rural"))


library(grid)
# Create histograms for specified RUCC_2023 code with additional options for cis and BorT
plot_histograms_by_rucc <- function(rucc_group) {
  
  # Filter data for the specified RUCC code
  filtered_data <- tworucc %>% filter(RUCC_group == rucc_group)

 
  # Create histograms for each category
  hist1 <- ggplot(filtered_data, aes(x = race_cis_sd_bgv_wt)) +
    geom_histogram(bins = 30, fill = "#1f77b4", alpha = 0.7) +
    theme_minimal(base_size = 14) + 
    labs(x = "Race", y = "Count")

  hist2 <- ggplot(filtered_data, aes(x = tract_cis_sd_bgv_wt)) +
    geom_histogram(bins = 30, fill = "#ff7f0e", alpha = 0.7) +
    theme_minimal(base_size = 14) +
    labs(x = "Tract", y = "Count")

  hist3 <- ggplot(filtered_data, aes(x = income_cis_sd_bgv_wt)) +
    geom_histogram(bins = 30, fill = "#2ca02c", alpha = 0.7) +
    theme_minimal(base_size = 14) +
    labs(x = "Income", y = "Count")
  
  # Define dynamic title
  main_title <- paste0("SD: ", rucc_group)

  

  # Arrange the plots in a grid with a title
  gridExtra::grid.arrange(
    grobs = list(
      grid::textGrob(main_title, gp = gpar(fontsize = 16, fontface = "bold")),  # Title
      hist1, hist2, hist3
    ))
  
}

plot_histograms_by_rucc(rucc_group = "Rural")
plot_histograms_by_rucc(rucc_group = "Urban")

```

## Correlations

Tract disparities and income disparities are more strongly correlated than tract disparities and race disparities. Income and race disparities are /slightly/ more correlated than tract and race disparities. The correlations below are calculated using Pearson's correlation coefficient and assume Normality and linearity.

```{r correlations}



library(corrplot)
library(ggplot2)
library(pheatmap)

# Assuming the necessary variables are in 'map_data'
# Select the relevant columns for correlation analysis
cor_data <- hist_data %>%
  select(
    tract_cis_sd_bgv_wt, 
    income_cis_sd_bgv_wt, 
    race_cis_sd_bgv_wt, 
  )

# Calculate correlation matrix
cor_matrix <- cor(cor_data, use = "complete.obs", method = "pearson")

# Visualize the correlation matrix using corrplot
corrplot(cor_matrix, method = "color", type = "upper", 
         col = colorRampPalette(c("pink", "white", "lightblue"))(200),
         title = "Correlation Heatmap", 
         mar = c(0,0,1,0))

# Alternatively, you can use pheatmap for a more interactive approach
pheatmap(cor_matrix, 
         display_numbers = TRUE, 
         color = colorRampPalette(c("pink", "white", "lightblue"))(100),
         main = "Correlation Heatmap", 
         fontsize = 12)

```

The strongest correlation occurs between tract and income, weakest between tract and race. All correlations are significant. The correlations below are calculated using Spearman's correlation test which is robust to nonlinear relationships.

```{r}
# Example: Calculate Spearman's correlation
race_inc <- cor.test(hist_data$race_cis_sd_bgv_wt, hist_data$income_cis_sd_bgv_wt, method = "spearman")

tract_inc <- cor.test(hist_data$tract_cis_sd_bgv_wt, hist_data$income_cis_sd_bgv_wt, method = "spearman")

tract_race <- cor.test(hist_data$tract_cis_sd_bgv_wt, hist_data$race_cis_sd_bgv_wt, method = "spearman")

race_inc
tract_inc
tract_race

```

## State-level rhos

```{r state level rho calcs }
library(dplyr)
library(purrr)

# Updated function to safely calculate Spearman's rho
get_spearman_rho <- function(x, y) {
  if (length(na.omit(x)) < 2 || length(na.omit(y)) < 2) {
    return(NA)  # Not enough data to compute correlation
  }
  cor.test(x, y, method = "spearman")$estimate
}

# Calculate Spearman's rho per state
rho_by_state <- hist_data %>%
  group_by(State) %>%
  summarise(
    race_inc_rho = get_spearman_rho(race_cis_sd_bgv_wt, income_cis_sd_bgv_wt),
    tract_inc_rho = get_spearman_rho(tract_cis_sd_bgv_wt, income_cis_sd_bgv_wt),
    tract_race_rho = get_spearman_rho(tract_cis_sd_bgv_wt, race_cis_sd_bgv_wt)
  )

```

```{r state level map function }
library(ggplot2)
library(maps)

# Load US states map
states_map <- map_data("state")

# Convert statecode to lowercase full names (you may need a lookup table here)
# This assumes statecode is a standard two-letter code
library(tibble)

state_lookup <- tibble::tibble(
  State = state.abb,
  statename = tolower(state.name)
)

# Join rho data with full state names
rho_by_state_map <- rho_by_state %>%
  left_join(state_lookup, by = "State") %>%
  filter(!is.na(statename)) # Remove states not matched

```

```{r maps themselves }
# Merge with map data
plot_data <- states_map %>%
  left_join(rho_by_state_map, by = c("region" = "statename"))

# Define a plotting function
plot_rho_map <- function(data, fill_col, title) {
  ggplot(data, aes(x = long, y = lat, group = group, fill = .data[[fill_col]])) +
    geom_polygon(color = "white") +
    coord_fixed(1.3) +
    scale_fill_viridis_c(option = "plasma", na.value = "gray90") +
    labs(title = title, fill = "Spearman's Ï") +
    theme_minimal()
}

# Create each map
map_race_inc <- plot_rho_map(plot_data, "race_inc_rho", "Race vs. Income Correlation by State")
map_tract_inc <- plot_rho_map(plot_data, "tract_inc_rho", "Tract vs. Income Correlation by State")
map_tract_race <- plot_rho_map(plot_data, "tract_race_rho", "Tract vs. Race Correlation by State")

# Display the maps
print(map_race_inc)
print(map_tract_inc)
print(map_tract_race)

```

## State-level SD

```{r Calculate the median for each state}

median_by_state <- hist_data %>%
  group_by(State) %>%
  summarise(
    median_tract = median(tract_cis_sd_bgv_wt, na.rm = TRUE),
    median_race = median(race_cis_sd_bgv_wt, na.rm = TRUE),
    median_income = median(income_cis_sd_bgv_wt, na.rm = TRUE),
    .groups = "drop"
  )




# Merge the median values with state names
median_by_state_map <- median_by_state %>%
  left_join(state_lookup, by = "State") %>%
  filter(!is.na(statename))  # Remove unmatched states


```

```{r make the map and print top 3 below}
library(ggplot2)
library(dplyr)

# Merge the state-level median values with the map data
plot_data <- states_map %>%
  left_join(median_by_state_map, by = c("region" = "statename"))

# Function to get the states with the highest median values
get_top_states <- function(data, fill_col, top_n = 3) {
  data %>%
    group_by(region) %>%
    summarise(top_value = max(.data[[fill_col]], na.rm = TRUE)) %>%
    arrange(desc(top_value)) %>%
    head(top_n) %>%
    pull(region)
}

# Function to plot the map and annotate the top states
plot_median_map <- function(data, fill_col, title, top_states) {
  ggplot(data, aes(x = long, y = lat, group = group, fill = .data[[fill_col]])) +
    geom_polygon(color = "white") +
    coord_fixed(1.3) +
    scale_fill_viridis_c(option = "plasma", na.value = "gray90") +
    labs(title = title, fill = "Median Value") +
    theme_minimal() +
    annotate("text", x = -125, y = 25, label = paste("Top States: ", paste(top_states, collapse = ", ")), 
             size = 5, color = "black", hjust = 0, vjust = 0)
}

# Get the top 5 states for each variable
top_states_tract <- get_top_states(plot_data, "median_tract")
top_states_race <- get_top_states(plot_data, "median_race")
top_states_income <- get_top_states(plot_data, "median_income")

# Create the maps for each variable
map_median_tract <- plot_median_map(plot_data, "median_tract", "Median Tract Disparity by State", top_states_tract)
map_median_race <- plot_median_map(plot_data, "median_race", "Median Race Disparity by State", top_states_race)
map_median_income <- plot_median_map(plot_data, "median_income", "Median Income Disparity by State", top_states_income)

# Display the maps
print(map_median_tract)
print(map_median_race)
print(map_median_income)

```

## States where tract disparities are greater than income disparities

```{r}
median_by_state %>% filter(median_income < median_tract)



```

## States where race disparities are greater than income disparities

```{r}
median_by_state %>% filter(median_income < median_race)
```

## Missingness

```{r venn diagram}

library(ggvenn)


# Step 2: Create subsets for the Venn diagram based on missing values
venn_data <- list(
  race = hist_data %>% filter(is.na(race_cis_sd_bgv_wt)) %>% pull(fipscode),
  tract = hist_data %>% filter(is.na(tract_cis_sd_bgv_wt)) %>% pull(fipscode),
  income = hist_data %>% filter(is.na(income_cis_sd_bgv_wt)) %>% pull(fipscode)
)

# Calculate total number of missing entries (only consider missing data)
total_missing <- length(unique(c(venn_data$race, venn_data$tract, venn_data$income)))



# Create Venn diagram using ggvenn
ggvenn(venn_data, 
       show_percentage = TRUE, 
       fill_color = c("lightblue", "lightgreen", "lightcoral"),
       stroke_color = "black")
      # title = "Venn Diagram of Missing Values for Race, Tract, and Income SD")

```

```{r table of missingness}
# Load the gt package
library(gt)

# Create the missing_counts dataframe
missing_counts <- data.frame(
  category = c("Race", "Tract", "Income"),
  count = c(length(venn_data$race), length(venn_data$tract), length(venn_data$income))
)

# Calculate percent missing for each category
missing_counts$percent_missing <- (missing_counts$count / nrow(hist_data)) * 100

# Use gt to create a simple, pretty table
missing_counts %>%
  gt() %>%
  tab_header(
    title = "Missing Data by Category"
  ) %>%
  cols_label(
    category = "Category",
    count = "Count",
    percent_missing = "Percent Missing"
  ) %>%
  tab_style(
    style = cell_borders(sides = "all", color = "black", weight = px(2)),
    locations = cells_body()
  ) %>%
  tab_options(
    table.width = pct(80),
    column_labels.font.size = 14,
    table.border.top.color = "black",
    table.border.bottom.color = "black"
  )

```

### Summary stats with two RUCC groups

Split is here: <https://www.ers.usda.gov/data-products/rural-urban-continuum-codes/documentation#:~:text=For%20Rural%2DUrban%20Continuum%20Codes,below%20250%2C000%20(code%203).>

```{r latest summary table}



# Load necessary libraries
library(dplyr)
library(gt)

# Assuming 'tworucc' is your dataset, and you have a column named 'RUCC_group'
# Calculate missing and available percentages, along with median, min, max for each variable

tworucc_summary <- tworucc %>%
  mutate(
    # Calculate missing data for each variable
    race_missing = sum(is.na(race_cis_sd_bgv_wt)),
    income_missing = sum(is.na(income_cis_sd_bgv_wt)),
    tract_missing = sum(is.na(tract_cis_sd_bgv_wt)),
    total_count = n(),
    
    # Calculate percent data available
    race_available_percent = (1 - race_missing / total_count) * 100,
    income_available_percent = (1 - income_missing / total_count) * 100,
    tract_available_percent = (1 - tract_missing / total_count) * 100
  ) %>%
  group_by(RUCC_group) %>%
  summarise(
    # Calculate missing counts
    race_missing = sum(is.na(race_cis_sd_bgv_wt)),
    income_missing = sum(is.na(income_cis_sd_bgv_wt)),
    tract_missing = sum(is.na(tract_cis_sd_bgv_wt)),
    
    # Calculate available percentages
    race_available_percent = (1 - race_missing / n()) * 100,
    income_available_percent = (1 - income_missing / n()) * 100,
    tract_available_percent = (1 - tract_missing / n()) * 100,
    
    # Median, min, and max for race, income, and tract (combined)
    race_stats = paste(
      round(median(race_cis_sd_bgv_wt, na.rm = TRUE), 4),
      "(", round(min(race_cis_sd_bgv_wt, na.rm = TRUE), 4),
      ",", round(max(race_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
    ),
    
    income_stats = paste(
      round(median(income_cis_sd_bgv_wt, na.rm = TRUE), 4),
      "(", round(min(income_cis_sd_bgv_wt, na.rm = TRUE), 4),
      ",", round(max(income_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
    ),
    
    tract_stats = paste(
      round(median(tract_cis_sd_bgv_wt, na.rm = TRUE), 4),
      "(", round(min(tract_cis_sd_bgv_wt, na.rm = TRUE), 4),
      ",", round(max(tract_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
    ),
    
    .groups = "drop"
  ) %>%
  bind_rows(
    # Calculate overall summary statistics (combined)
    tibble(
      RUCC_group = "Overall",
      race_missing = sum(is.na(tworucc$race_cis_sd_bgv_wt)),
      income_missing = sum(is.na(tworucc$income_cis_sd_bgv_wt)),
      tract_missing = sum(is.na(tworucc$tract_cis_sd_bgv_wt)),
      
      race_available_percent = (1 - sum(is.na(tworucc$race_cis_sd_bgv_wt)) / nrow(tworucc)) * 100,
      income_available_percent = (1 - sum(is.na(tworucc$income_cis_sd_bgv_wt)) / nrow(tworucc)) * 100,
      tract_available_percent = (1 - sum(is.na(tworucc$tract_cis_sd_bgv_wt)) / nrow(tworucc)) * 100,
      
      race_stats = paste(
        round(median(tworucc$race_cis_sd_bgv_wt, na.rm = TRUE), 4),
        "(", round(min(tworucc$race_cis_sd_bgv_wt, na.rm = TRUE), 4),
        ",", round(max(tworucc$race_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
      ),
      
      income_stats = paste(
        round(median(tworucc$income_cis_sd_bgv_wt, na.rm = TRUE), 4),
        "(", round(min(tworucc$income_cis_sd_bgv_wt, na.rm = TRUE), 4),
        ",", round(max(tworucc$income_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
      ),
      
      tract_stats = paste(
        round(median(tworucc$tract_cis_sd_bgv_wt, na.rm = TRUE), 4),
        "(", round(min(tworucc$tract_cis_sd_bgv_wt, na.rm = TRUE), 4),
        ",", round(max(tworucc$tract_cis_sd_bgv_wt, na.rm = TRUE), 4), ")"
      )
    )
  )

# Create the table using gt
tworucc_summary %>%
  gt() %>%
  tab_header(
    title = "Summary of Homeownership Rates by RUCC Group"
  ) %>%
  cols_label(
    RUCC_group = "RUCC Group",
    race_available_percent = "Race Data Available (%)",
    income_available_percent = "Income Data Available (%)",
    tract_available_percent = "Tract Data Available (%)",
    race_stats = "Race (Median, Min, Max)",
    income_stats = "Income (Median, Min, Max)",
    tract_stats = "Tract (Median, Min, Max)"
  ) %>%
  tab_style(
    style = cell_borders(sides = "all", color = "black", weight = px(2)),
    locations = cells_body()
  ) %>%
  tab_options(
    table.width = pct(90),
    column_labels.font.size = 14,
    table.border.top.color = "black",
    table.border.bottom.color = "black"
  ) %>%
  tab_spanner(
    label = "Data Availability",
    columns = vars(race_available_percent, income_available_percent, tract_available_percent)
  ) %>%
  tab_spanner(
    label = "Summary Statistics (Median, Min, Max)",
    columns = vars(race_stats, income_stats, tract_stats)
  )


```

Medians

```{r}
olddata = haven::read_sas("P:/CH-Ranking/Data/2024/6 Measure Datasets/Additional Measures/v153.sas7bdat")



# Filter the data for different variables where each is not NA
filtered_race <- hist_data %>%
  filter(!is.na(race_cis_sd_bgv_wt))

filtered_income <- hist_data %>%
  filter(!is.na(income_cis_sd_bgv_wt))

filtered_tract <- hist_data %>%
  filter(!is.na(tract_cis_sd_bgv_wt))

# Merge olddata with filtered hist_data by statecode and countycode
merged_race <- olddata %>%
  inner_join(filtered_race, by = c("statecode", "countycode"))

merged_income <- olddata %>%
  inner_join(filtered_income, by = c("statecode", "countycode"))

merged_tract <- olddata %>%
  inner_join(filtered_tract, by = c("statecode", "countycode"))

# Calculate the median of v153_rawvalue for each filtered dataset
median_race <- median(merged_race$v153_rawvalue, na.rm = TRUE)
median_income <- median(merged_income$v153_rawvalue, na.rm = TRUE)
median_tract <- median(merged_tract$v153_rawvalue, na.rm = TRUE)

# Create a table using gt to display the median values
median_table <- tibble(
  Variable = c("v153_rawvalue with race data", "v153_rawvalue with income data", "v153_rawvalue with tract data"),
  Median_Value = c(median_race, median_income, median_tract)
) %>%
  gt() %>%
  tab_header(
    title = "Median Values of v153_rawvalue with available data"
  ) %>% 
  cols_label(
    Variable = "Variable",
    Median_Value = "Median Value"
  ) %>%
  tab_style(
    style = cell_borders(sides = "all", color = "black", weight = px(2)),
    locations = cells_body()
  ) %>%
  tab_options(
    table.width = pct(70),
    column_labels.font.size = 14,
    table.border.top.color = "black",
    table.border.bottom.color = "black"
  )

# Display the table
median_table

```
